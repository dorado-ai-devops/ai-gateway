# ğŸ” ai-gateway

> Microservicio Flask que actÃºa como gateway inteligente entre Jenkins, los microservicios IA (`ai-logs-analyze`, `ai-helm-linter`, `ai-pipeline-gen`) y los modelos LLM locales (Ollama) o remotos (OpenAI). Este componente organiza el flujo de informaciÃ³n, dirige las peticiones y establece fallback entre motores de IA.

---

## ğŸšª FunciÃ³n Principal

Centraliza las llamadas desde Jenkins y despacha las peticiones a los microservicios AI del entorno `DEVOPS-AI-LAB`, utilizando como backend modelos de lenguaje (LLMs) para:

- ğŸ“Š AnÃ¡lisis de logs
- ğŸ§ª ValidaciÃ³n y linting de Helm Charts
- âš™ï¸ GeneraciÃ³n automÃ¡tica de pipelines CI/CD desde lenguaje natural

---

## ğŸŒ Endpoints

### `POST /analyze-log`

Analiza registros CI/CD con LLMs.

**Payload:**
```json
{
  "logfile": "logs/build.log",
  "model": "mistral",
  "prompt_template": "log_analysis"
}
```

â†’ Redirige internamente al microservicio `ai-logs-analyze`.

---

### `POST /lint-chart`

Valida un Helm Chart mediante IA.

**Payload (multipart/form-data):**

- `chart`: archivo `.tgz` del Helm Chart
- `mode`: `"ollama"` o `"openai"`
- `ruleset`: `"default"` (opcional)

â†’ Redirige a `ai-helm-linter`.

---

### `POST /generate-pipeline`

Convierte lenguaje natural en definiciÃ³n de pipeline CI/CD.

**Payload:**
```json
{
  "description": "Crea un pipeline que construya, testee y despliegue en Kubernetes con Helm",
  "target": "jenkins"
}
```

â†’ Llama a `ai-pipeline-gen`.

---

### `GET /health`

Respuesta: `200 OK`  
Sirve para verificar que el gateway estÃ¡ operativo.

---

## ğŸ§  Inteligencia Adaptativa

- Utiliza por defecto **modelos locales en Ollama** (por ejemplo, Mistral 7b)
- Si falla Ollama, hace fallback automÃ¡tico a **OpenAI GPT-4o** (si estÃ¡ configurado)
- Toda la lÃ³gica de redirecciÃ³n, autenticaciÃ³n y enrutamiento ocurre en `ai-gateway`

---

## ğŸ“¦ Estructura del Proyecto

```
ai-gateway/
â”œâ”€â”€ app.py                 # Servidor Flask con todos los endpoints
â”œâ”€â”€ routes/                # MÃ³dulos especÃ­ficos de cada endpoint
â”‚   â”œâ”€â”€ analyze_log.py
â”‚   â”œâ”€â”€ lint_chart.py
â”‚   â””â”€â”€ generate_pipeline.py
â”œâ”€â”€ clients/               # Conexiones con microservicios y modelos
â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”œâ”€â”€ openai_client.py
â”‚   â””â”€â”€ service_dispatcher.py
â”œâ”€â”€ config/                # ParÃ¡metros, paths, fallbacks
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

## âš™ï¸ Ejecutar

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python3 app.py
```

---

## ğŸ§© IntegraciÃ³n con Jenkins

Desde Jenkins puedes llamar directamente al gateway para despachar tareas:

```groovy
def jsonPayload = '''
{
  "description": "Quiero un pipeline para test + deploy en K8s",
  "target": "jenkins"
}
'''

sh '''
curl -X POST http://ai-gateway.devops-ai.svc.cluster.local:5000/generate-pipeline   -H "Content-Type: application/json"   -d '${jsonPayload}'
'''
```

---

## ğŸ§  Rol en el sistema

- Es la entrada Ãºnica al backend de IA
- Se desplegarÃ¡ como microservicio Flask en Kubernetes
- Todo lo expuesto serÃ¡ gestionado por ArgoCD vÃ­a manifiestos GitOps
- Requiere los microservicios `ai-logs-analyze`, `ai-helm-linter` y `ai-pipeline-gen` desplegados previamente

---

## ğŸ”’ Seguridad futura

- AutenticaciÃ³n por token si se publica
- ValidaciÃ³n de entradas y sanitizaciÃ³n
- Logging estructurado con nivel de detalle ajustable

---

## ğŸ”® Futuros mÃ³dulos posibles

- `/explain-error`: analizar traceback o errores y devolver explicaciÃ³n
- `/summarize-pipeline`: resumen de CI/CD para auditorÃ­a
- `/compare-logs`: diff de logs entre dos ejecuciones

---

## ğŸ‘¨â€ğŸ’» Autor

**Dani** â€“ [@dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ›¡ Licencia

Licencia PÃºblica General GNU v3.0