# ğŸ” ai-gateway

> Flask microservice that acts as an intelligent gateway between Jenkins, AI microservices (`ai-log-analyzer`, `ai-helm-linter`, `ai-pipeline-gen`), and local (Ollama) or remote (OpenAI) LLMs. This component orchestrates request routing, fallback handling, and MCP message generation.

---

## ğŸšª Main Purpose

Centralizes Jenkins calls and dispatches requests to AI services within the `devops-ai-lab` environment, leveraging LLMs for:

- ğŸ“Š Log analysis
- ğŸ§ª Helm Chart validation
- âš™ï¸ CI/CD pipeline generation from natural language

---

## ğŸŒ Endpoints

### `POST /analyze-log`

Analyzes CI/CD logs using LLMs.

**Payload:**
```json
{
  "logfile": "logs/build.log",
  "model": "mistral",
  "prompt_template": "log_analysis"
}
```
â†’ Internally forwarded to `ai-log-analyzer`.

---

### `POST /lint-chart`

Audits a Helm Chart using AI.

**Payload (multipart/form-data):**
- `chart`: `.tgz` archive of the Helm Chart
- `mode`: `"ollama"` or `"openai"`
- `ruleset`: `"default"` (optional)

â†’ Forwards to `ai-helm-linter`.

---

### `POST /generate-pipeline`

Generates a CI/CD pipeline definition from natural language.

**Payload:**
```json
{
  "description": "Pipeline with test and Helm deploy",
  "target": "jenkins"
}
```
â†’ Forwards to `ai-pipeline-gen`.

---

### `GET /health`

Response: `200 OK`  
Used to verify the gateway is live.

---

## ğŸ“¦ Project Structure

```
ai-gateway/
â”œâ”€â”€ app.py                 # Main Flask server
â”œâ”€â”€ routes/                # Endpoint definitions
â”‚   â”œâ”€â”€ analyze_log.py
â”‚   â”œâ”€â”€ lint_chart.py
â”‚   â””â”€â”€ generate_pipeline.py
â”œâ”€â”€ clients/               # Microservice dispatchers
â”‚   â”œâ”€â”€ service_dispatcher.py
â”‚   â””â”€â”€ mcp_client.py
â”œâ”€â”€ config.py              # Service URLs, timeout, default LLM
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Makefile               # Build and deployment automation
â”œâ”€â”€ Dockerfile             # Container image
â””â”€â”€ run_*.sh               # Local test scripts
```

---

## âš™ï¸ Local Execution

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python3 app.py
```

---

## ğŸ” Jenkins Integration Example

```groovy
def jsonPayload = '''
{
  "description": "Basic test and deploy pipeline",
  "target": "jenkins"
}
'''

sh '''
curl -X POST http://ai-gateway.devops-ai.svc.cluster.local:5000/generate-pipeline \
     -H "Content-Type: application/json" \
     -d '${jsonPayload}'
'''
```

---

## ğŸ§  Adaptive Intelligence

- Tries **local Ollama (Mistral)** model first
- Falls back to **OpenAI GPT-4o** if needed
- Behavior controlled via `service_dispatcher.py`

---

## ğŸ“¥ MCP Logging

On successful LLM dispatch (with `prompt_path` and `response_path`), the gateway:

- Sends a structured **MCP message** to `ai-mcp-server`
- Logs source (`ai-gateway`), type, microservice, summary, and tags
- Useful for observability and audit trails

---

## ğŸ” Security & Next Steps

- Token-based authentication (planned)
- Input validation & sanitization in place
- Structured logging (WIP)

---

## ğŸ”® Planned Modules

- `/explain-error`: traceback analysis
- `/summarize-pipeline`: CI/CD definition summarizer
- `/compare-logs`: diffing log sequences

---

## ğŸ‘¨â€ğŸ’» Author

**Dani** â€“ [@dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ›¡ License

GNU General Public License v3.0